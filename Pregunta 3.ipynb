{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">a) Construya un dataframe con los datos a analizar. Determine cuántas clases existen, cuántos registros por clase y describa el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">b) Construya un conjunto de entrenamiento y otro de pruebas, a través de una máscara aleatoria, para verificar los resultados de los algoritmos. Genere un conjunto de validación si estima conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este paso lo realizamos después de filtrar y preprocesar los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">c) Construya las representaciones de los datos con los que trabajará, ya sea para las entradas de los modelos como para las salidas. Recuerde que tendrá que codificar las distintas clases como valores numéricos enteros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "empty=0\n",
    "sadness=1\n",
    "enthusiasm=2\n",
    "neutral=3\n",
    "worry=4\n",
    "surprise=5\n",
    "love=6\n",
    "fun=7\n",
    "happines=8\n",
    "hate=9\n",
    "boredom=10\n",
    "anger=11\n",
    "relief=12\n",
    "40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral       8638\n",
      "worry         8459\n",
      "happiness     5209\n",
      "sadness       5165\n",
      "love          3842\n",
      "surprise      2187\n",
      "fun           1776\n",
      "relief        1526\n",
      "hate          1323\n",
      "empty          827\n",
      "enthusiasm     759\n",
      "boredom        179\n",
      "anger          110\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentint = np.empty(40000, dtype=object)\n",
    "for i in range (40000):\n",
    "    if df['sentiment'][i]=='empty':\n",
    "        sentimentint[i]='0'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='sadness':\n",
    "        sentimentint[i]='1'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='enthusiasm':\n",
    "        sentimentint[i]='2'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='neutral':\n",
    "        sentimentint[i]='3'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='worry':\n",
    "        sentimentint[i]='4'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='surprise':\n",
    "        sentimentint[i]='5'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='love':\n",
    "        sentimentint[i]='6'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='fun':\n",
    "        sentimentint[i]='7'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='happiness':\n",
    "        sentimentint[i]='8'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='hate':\n",
    "        sentimentint[i]='9'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='boredom':\n",
    "        sentimentint[i]='10'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='anger':\n",
    "        sentimentint[i]='11'\n",
    "        continue\n",
    "    if df['sentiment'][i]=='relief':\n",
    "        sentimentint[i]='12'\n",
    "        continue\n",
    "    sentimentint[i]='0'\n",
    "        \n",
    "df['sentimentint'] = sentimentint    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>sentimentint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment         author  \\\n",
       "0  1956967341       empty     xoshayzers   \n",
       "1  1956967666     sadness      wannamama   \n",
       "2  1956967696     sadness      coolfunky   \n",
       "3  1956967789  enthusiasm    czareaquino   \n",
       "4  1956968416     neutral      xkilljoyx   \n",
       "5  1956968477       worry  xxxPEACHESxxx   \n",
       "6  1956968487     sadness       ShansBee   \n",
       "7  1956968636       worry       mcsleazy   \n",
       "8  1956969035     sadness    nic0lepaula   \n",
       "9  1956969172     sadness     Ingenue_Em   \n",
       "\n",
       "                                             content sentimentint  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...            0  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...            1  \n",
       "2                Funeral ceremony...gloomy friday...            1  \n",
       "3               wants to hang out with friends SOON!            2  \n",
       "4  @dannycastillo We want to trade with someone w...            3  \n",
       "5  Re-pinging @ghostridah14: why didn't you go to...            4  \n",
       "6  I should be sleep, but im not! thinking about ...            1  \n",
       "7               Hmmm. http://www.djhero.com/ is down            4  \n",
       "8            @charviray Charlene my love. I miss you            1  \n",
       "9         @kelcouch I'm sorry  at least it's Friday?            1  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### preprocesamiento de texto df[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#función remove stopWords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "def stopWords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in cachedStopWords])\n",
    "    return text\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#función apply stemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stemmerWords(text):\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# transformamos los datos con la función lower()\n",
    "df[\"content\"]=df[\"content\"].str.lower()\n",
    "\n",
    "#idea... agregar una columna extra al final que cuente la cantidad de etiquetas @etiqueta\n",
    "# eliminamos todas las @etiquetas de los usuarios\n",
    "df[\"content\"] = df[\"content\"].apply(lambda x: \" \".join(x for x in x.split() if not x.startswith('@')))\n",
    "\n",
    "# quitamos todos los carácteres que no son ni letras ni números\n",
    "df[\"content\"]=df[\"content\"].replace('[^a-z0-9]', ' ', regex = True)\n",
    "\n",
    "# df[\"content\"]=df[\"content\"].replace(r'(^.*mm.*$)', 'mmmm')\n",
    "df[\"content\"] = df[\"content\"].replace('[a-zA-Z]*m{2}[a-zA-Z]*', 'mmm', regex = True)\n",
    "\n",
    "# df[\"content\"]=df[\"content\"].replace(r'(^.*mm.*$)', 'mmmm')\n",
    "df[\"content\"] = df[\"content\"].replace('[a-zA-Z]*ugh[a-zA-Z]*', 'ugh', regex = True)\n",
    "\n",
    "\n",
    "#quitando stopwords\n",
    "# df[\"content\"] = df[\"content\"].apply(lambda x: stopWords(x))\n",
    "\n",
    "#Stemmer words \n",
    "df[\"content\"] = df[\"content\"].apply(lambda x: stemmerWords(x))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se trabaja la letra B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape= (40000, 5)\n",
      "df train shape= (35970, 5)\n",
      "df test shape= (4030, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>sentimentint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>i know i was listenin to bad habit earlier and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>layin n bed with a headach ugh waitin on your ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>funer ceremoni gloomi friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>want to hang out with friend soon</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>we want to trade with someon who has houston t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>re ping whi didn t you go to prom bc my bf did...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>i should be sleep but im not think about an ol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>mmm http www djhero com is down</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>charlen my love i miss you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>i m sorri at least it s friday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1956969456</td>\n",
       "      <td>neutral</td>\n",
       "      <td>feinyheiny</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1956969531</td>\n",
       "      <td>worry</td>\n",
       "      <td>dudeitsmanda</td>\n",
       "      <td>choke on her retain</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1956970047</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Danied32</td>\n",
       "      <td>ugh i have to beat this stupid song to get to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1956970424</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Samm_xo</td>\n",
       "      <td>if u watch the hill in london u will realis wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1956970860</td>\n",
       "      <td>surprise</td>\n",
       "      <td>okiepeanut93</td>\n",
       "      <td>got the news</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1956971077</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sim_34</td>\n",
       "      <td>the storm is here and the electr is gone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1956971170</td>\n",
       "      <td>love</td>\n",
       "      <td>poppygallico</td>\n",
       "      <td>agre</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1956971206</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brokenangel1982</td>\n",
       "      <td>so sleepi again and it s not even that late i ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1956971473</td>\n",
       "      <td>worry</td>\n",
       "      <td>LCJ82</td>\n",
       "      <td>ladi gaga tweet about not be impress by her vi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1956971586</td>\n",
       "      <td>sadness</td>\n",
       "      <td>cleepow</td>\n",
       "      <td>how are you convinc that i have alway want you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id   sentiment           author  \\\n",
       "0   1956967341       empty       xoshayzers   \n",
       "1   1956967666     sadness        wannamama   \n",
       "2   1956967696     sadness        coolfunky   \n",
       "3   1956967789  enthusiasm      czareaquino   \n",
       "4   1956968416     neutral        xkilljoyx   \n",
       "5   1956968477       worry    xxxPEACHESxxx   \n",
       "6   1956968487     sadness         ShansBee   \n",
       "7   1956968636       worry         mcsleazy   \n",
       "8   1956969035     sadness      nic0lepaula   \n",
       "9   1956969172     sadness       Ingenue_Em   \n",
       "10  1956969456     neutral       feinyheiny   \n",
       "11  1956969531       worry     dudeitsmanda   \n",
       "12  1956970047     sadness         Danied32   \n",
       "13  1956970424     sadness          Samm_xo   \n",
       "14  1956970860    surprise     okiepeanut93   \n",
       "15  1956971077     sadness           Sim_34   \n",
       "16  1956971170        love     poppygallico   \n",
       "17  1956971206     sadness  brokenangel1982   \n",
       "18  1956971473       worry            LCJ82   \n",
       "19  1956971586     sadness          cleepow   \n",
       "\n",
       "                                              content sentimentint  \n",
       "0   i know i was listenin to bad habit earlier and...            0  \n",
       "1   layin n bed with a headach ugh waitin on your ...            1  \n",
       "2                        funer ceremoni gloomi friday            1  \n",
       "3                   want to hang out with friend soon            2  \n",
       "4   we want to trade with someon who has houston t...            3  \n",
       "5   re ping whi didn t you go to prom bc my bf did...            4  \n",
       "6   i should be sleep but im not think about an ol...            1  \n",
       "7                     mmm http www djhero com is down            4  \n",
       "8                          charlen my love i miss you            1  \n",
       "9                      i m sorri at least it s friday            1  \n",
       "10                                   cant fall asleep            3  \n",
       "11                                choke on her retain            4  \n",
       "12  ugh i have to beat this stupid song to get to ...            1  \n",
       "13  if u watch the hill in london u will realis wh...            1  \n",
       "14                                       got the news            5  \n",
       "15           the storm is here and the electr is gone            1  \n",
       "16                                               agre            6  \n",
       "17  so sleepi again and it s not even that late i ...            1  \n",
       "18  ladi gaga tweet about not be impress by her vi...            4  \n",
       "19  how are you convinc that i have alway want you...            1  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(df)) < 0.9\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "print \"df shape= \" +str(df.shape)\n",
    "print \"df train shape= \" +str(df_train.shape)\n",
    "print \"df test shape= \" +str(df_test.shape)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i know i was listenin to bad habit earlier and...\n",
       "1    layin n bed with a headach ugh waitin on your ...\n",
       "2                         funer ceremoni gloomi friday\n",
       "3                    want to hang out with friend soon\n",
       "4    we want to trade with someon who has houston t...\n",
       "5    re ping whi didn t you go to prom bc my bf did...\n",
       "6    i should be sleep but im not think about an ol...\n",
       "7                      mmm http www djhero com is down\n",
       "8                           charlen my love i miss you\n",
       "9                       i m sorri at least it s friday\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"content\"][0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    2\n",
       "4    3\n",
       "5    4\n",
       "6    1\n",
       "7    4\n",
       "8    1\n",
       "9    1\n",
       "Name: sentimentint, dtype: object"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"sentimentint\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2),min_df=2,binary='False')\n",
    "vectorizer.fit(df_train[\"content\"])\n",
    "\n",
    "#obtenemos las matrices de features utilizando la función vector anterior\n",
    "X_tfidf = vectorizer.transform(df_train[\"content\"])\n",
    "X_vfidf = vectorizer.transform(df_test[\"content\"]) \n",
    "\n",
    "X = hstack([X_tfidf])\n",
    "Xval = hstack([X_vfidf])\n",
    "\n",
    "y = df_train[\"sentimentint\"]\n",
    "yval = df_test[\"sentimentint\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">d) Entrene y compare al menos 4 de los diferentes clasificadores vistos en clases para clasificación (por ejemplo: Navie Bayes, Multinomial Naive Bayes, LDA, QDA, Regresión logı́stica y Perceptrón). Recuerde que algunos son extendidos por defecto a múltiples clases para detectar emociones en cada tweet, sin embargo, otros deben ser extentidos a través de otras técnicas, tal como One vs One y One vs All/Rest. Muestre tabla o gráfico resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6261050875729774\n",
      "0.33523573200992557\n",
      "0.6552682791214901\n",
      "0.3389578163771712\n"
     ]
    }
   ],
   "source": [
    "#utilizando Multinomial naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modelMNB = MultinomialNB()\n",
    "modelMNB.fit(X, y)\n",
    "print modelMNB.score(X, y)\n",
    "print modelMNB.score(Xval, yval)\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "classifMNB = OneVsRestClassifier(MultinomialNB())\n",
    "classifMNB.fit(X, y)\n",
    "print classifMNB.score(X,y)\n",
    "print classifMNB.score(Xval,yval)\n",
    "#SE APRECIAN MEJORAS TRAS APLICAR OneVSRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5782040589380039\n",
      "0.23225806451612904\n",
      "0.808868501529052\n",
      "0.29851116625310176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "Cs = 100000\n",
    "modelPerceptron = Perceptron(penalty='l2', alpha=1.0/Cs, max_iter=200)\n",
    "modelPerceptron.fit(X,y)\n",
    "\n",
    "print modelPerceptron.score(X,y)\n",
    "print modelPerceptron.score(Xval,yval)\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "#example\n",
    "classifPERCEP = OneVsOneClassifier(Perceptron(penalty='l2', alpha=1.0/Cs, max_iter=200))\n",
    "classifPERCEP.fit(X, y)\n",
    "print classifPERCEP.score(X,y)\n",
    "print classifPERCEP.score(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981845982763414\n",
      "0.2826302729528536\n",
      "0.9818181818181818\n",
      "0.2826302729528536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Cs = 100\n",
    "modelLogistic = LogisticRegression(penalty='l2', C=Cs,max_iter=200)\n",
    "modelLogistic.fit(X,y)   \n",
    "print modelLogistic.score(X,y)\n",
    "print modelLogistic.score(Xval,yval)\n",
    "\n",
    "classifLOGIS = OneVsRestClassifier(LogisticRegression(penalty='l2', C=Cs,max_iter=200))\n",
    "classifLOGIS.fit(X, y)\n",
    "print classifLOGIS.score(X,y)\n",
    "print classifLOGIS.score(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "modelQDA = QuadraticDiscriminantAnalysis()\n",
    "modelQDA.fit(asdf, y)\n",
    "print modelQDA.score(X, y)\n",
    "print modelQDA.score(Xval, yval)\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "classifQDA= OneVsRestClassifier(GaussianNB())\n",
    "classifQDA.fit(X, y)\n",
    "print classifQDA.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No logramos hacer funcionar el método QDA debido a problemas con el lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">e) Utilice la técnica de ECOC (Error-Correcting Output-Code) para extender a multiclases algunos de los clasificadores utilizados en d). Comente lo que hace la técnica y los resultados observados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-395-be0efa701a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutputCodeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutputCodeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/multiclass.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \"\"\"\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             raise ValueError(\"code_size should be greater than 0, got {0}\"\n",
      "\u001b[0;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[0;32m--> 431\u001b[0;31m                                       force_all_finite)\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gabriel/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[1;32m    276\u001b[0m                         \u001b[0;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[0;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OutputCodeClassifier\n",
    "clf = OutputCodeClassifier(Perceptron(penalty='l2', alpha=1.0/100000, max_iter=200),code_size=2, random_state=0)\n",
    "clf.fit(X, y)\n",
    "print clf.score(X,y)\n",
    "print clf.score(Xval,yval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No logramos hacer funcionar ECOC debido a problemas con el lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">f) Evalúe la métrica de accuracy sobre el conjunto de pruebas del mejor clasificador encontrado.\n",
    "Recuerde que puede acudir a otras métricas para tener otras visiones de lo que está haciendo el modelo de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33548387096774196"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB(alpha=1.2)\n",
    "model.fit(X, y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(Xval)\n",
    "y_true = yval\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">g) Intente mejorar su resultado considerablemente a través de alguna mejora novedosa. Se espera que supere el 35% de accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El máximo obtenido de accuracy fue de 0.335 \n",
    "No se pudo mejorar.\n",
    "Para obtener este accuracy se removieron los tags del tipo @nombre de los tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
